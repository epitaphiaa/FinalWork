История машинного обучения началась в середине XX века. В 1950 году Алан Тьюринг предложил концепцию «Тьюринг-теста», а в 1952 году Артур Самуэль разработал первую программу для игры в шашки, способную обучаться. В 1957 году Фрэнк Розенблатт создал перцептрон — простой нейрон, который мог обучаться и классифицировать данные.
В 1960-х годах были разработаны алгоритмы, такие как ближайший сосед и линейная регрессия, а в 1969 году Марвин Минский и Сеймур Пейперт опубликовали книгу «Perceptrons», указав на ограничения перцептронов. В 1980-х годах произошёл всплеск интереса к нейронным сетям благодаря алгоритму обратного распространения ошибки, который позволил обучать многослойные нейронные сети.
В 1990-х годах произошёл значительный прогресс в машинном обучении благодаря развитию вычислительных мощностей и доступности больших объёмов данных. Были разработаны алгоритмы, такие как SVM и случайные леса, ставшие основными инструментами исследователей и практиков машинного обучения.
В начале XXI века машинное обучение стало активно применяться в различных областях, таких как биоинформатика, обработка естественного языка и компьютерное зрение. В 2006 году Джеффри Хинтон представил концепцию глубокого обучения, которое позволило создавать многослойные нейронные сети с высокой производительностью.
В 2010-х годах глубокое обучение стало основным направлением в машинном обучении благодаря успехам в распознавании изображений и речи. В 2020-х годах технологии, такие как GAN и трансформеры, открыли новые возможности для создания искусственного интеллекта, способного генерировать тексты, изображения и видео.